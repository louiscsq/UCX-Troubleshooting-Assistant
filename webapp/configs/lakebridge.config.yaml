# Project Configuration
# Edit this file to customize the troubleshooting assistant for different repositories

# Project Identity
project_name: "Lakebridge"

# UI Text
ui_title: "Lakebridge Troubleshooting Assistant"
ui_tagline: "üí° **Lakebridge Troubleshooting Assistant** - Get help with DBSQL Migration issues, installation problems, and assessment errors. Describe your issue and I'll provide specific guidance!"
chat_placeholder: "Describe your Lakebridge issue ..."

# Sidebar
sidebar_header: "Common Troubleshooting Examples"
sidebar_installation_label: "üìã Installation Checklist"
sidebar_installation_title: "Installation Checklist"
sidebar_assessment_label: "üîç Assessment Checklist"
sidebar_assessment_title: "Assessment Checklist"
sidebar_errors_label: "üìö Common Errors"
sidebar_errors_title: "Common Lakebridge Errors"

# PDF Settings
pdf_filename_prefix: "Lakebridge_Response"
pdf_title: "Lakebridge Troubleshooting Assistant Response"
pdf_download_label: "Ready for customer documentation"

# Checklists
installation_checklist:
  - "‚úì Verify you have Databricks workspace administrator privileges"
  - "‚úì Ensure Python 3.10+ is installed"
  - "‚úì Update Databricks CLI to v0.213 or higher"
  - "‚úì Verify Unity Catalog is enabled in your workspace"
  - "‚úì Check network connectivity to external resources if using external HMS"
  - "‚úì Ensure sufficient compute resources are available"
  - "‚úì Verify authentication credentials are valid"
  - "‚úì Check workspace storage permissions"

assessment_checklist:
  - "‚úì Lakebridge is successfully installed"
  - "‚úì Authentication is properly configured"
  - "‚úì Assessment cluster is running and accessible"
  - "‚úì Required permissions are granted for data scanning"
  - "‚úì External data sources are accessible (if applicable)"
  - "‚úì Sufficient workspace storage for assessment results"
  - "‚úì Network connectivity to all data sources"

# Common Errors
errors:
  insufficient_privileges:
    error: "Insufficient privileges for Lakebridge installation"
    solution: "Ensure you have Databricks workspace administrator privileges. Lakebridge requires admin access to deploy assets into the workspace."
    details: "The installation process needs to create workflows, clusters, and other workspace resources."
  
  python_version:
    error: "Python version compatibility issues"
    solution: "Upgrade to Python 3.10 or later. Lakebridge requires modern Python features for proper operation."
    details: "Check your cluster's Python version and ensure it meets the minimum requirements."
  
  databricks_cli:
    error: "Databricks CLI issues"
    solution: "Update Databricks CLI to v0.213 or higher. Older versions may have compatibility issues."
    details: "Run 'databricks version' to check current version and 'pip install --upgrade databricks-cli' to update."
  
  authentication:
    error: "Authentication failures during Lakebridge operations"
    solution: "Verify your authentication credentials. Use DATABRICKS_HOST and DATABRICKS_TOKEN environment variables or --profile flag."
    details: "Check token validity and workspace permissions."
  
  external_hms:
    error: "External Hive Metastore connectivity issues"
    solution: "Verify network configuration and HMS connectivity. Ensure firewall rules allow communication."
    details: "Check HMS endpoints, credentials, and network policies."
  
  cluster_config:
    error: "Cluster configuration or resource issues"
    solution: "Check cluster policies and resource availability. Ensure sufficient compute resources are allocated."
    details: "Review cluster logs and resource quotas."
  
  unity_catalog_not_enabled:
    error: "Unity Catalog not enabled in workspace"
    solution: "Enable Unity Catalog in your Databricks workspace. Contact your workspace admin if needed."
    details: "Lakebridge requires Unity Catalog to be enabled for migration operations."

# Agent Configuration
agent:
  llm_endpoint: "databricks-claude-sonnet-4-5"
  
  system_prompt: |
    You are a Lakebridge expert assistant with access to the Lakebridge codebase, documentation, and internal troubleshooting guides. Lakebridge is a comprehensive toolkit for SQL migration to Databricks, covering three main phases: Assessment (profiling and analyzing SQL workloads), Conversion (transpiling SQL using BladeBridge or Morpheus), and Reconciliation (validating migrated data).

    RESPONSE GUIDELINES:
    - Be concise and direct unless the user requests details or clarification is essential. Do not overexplain or make assumptions. Aim for at maximum 200 words in the final answer (unless absolutely necessary). Do not repeat yourself. Do not add tables, matrices, warnings, best practices, summaries unless explicitly asked for.
    - Verify all functionality and commands exist in the codebase/documentation before confirming them
    - If information is unavailable or uncertain, clearly state that you don't have enough information to answer this.

    REASONING PROCESS:
    - Before calling any tool, explain what information you're looking for and why
    - After receiving tool results, analyze what you learned and determine if you need more information
    - If you need to call multiple tools, explain your strategy first
    - Synthesize information from multiple sources before providing your final answer

    CRITICAL CONSIDERATIONS:
    - Source platform differences: Lakebridge supports multiple SQL platforms (DataStage, Netezza, Oracle, Snowflake, SQL Server, Teradata) with different capabilities
    - Transpiler options: BladeBridge (mature, handles wide range of dialects and ETL/orchestration) vs Morpheus (next-gen, smaller dialect set, includes experimental dbt support)
    - Migration phases: Be clear about whether the question relates to Assessment (pre-migration), Conversion (transpiling), or Reconciliation (post-migration validation)
    - Out-of-the-box usage: Lakebridge is designed for use without code modifications. Users will call the Lakebridge tools and utilities. They cannot interact with specific python functions that are inside the library.
    - If a feature doesn't exist but could be easily implemented, suggest the user request it from the Lakebridge development team rather than implementing it themselves

    VALIDATION RULES:
    - Never say a feature exists based solely on user questions. Validate with the codebase and documentation
    - Never say a command exists without verification. Validate with the codebase and documentation
    - Only say something is possible after validating with the codebase and documentation
    - Only provide solutions that are confirmed to work in the codebase and documentation
  
  tools:
    docs_retriever:
      name: "docs_retriever"
      description: "Retrieves Lakebridge documentation including user guides, CLI commands, workflow descriptions, and feature explanations. Use this for understanding user-facing functionality and usage patterns. But always confirm with the codebase"
      num_results: 10
    
    codebase_retriever:
      name: "codebase_retriever"
      description: "Retrieves Lakebridge source code including Python/SQL function definitions, classes, and implementation details. Use this to verify implementation details, validate that features exist, or understand technical internals. Always cross-reference with documentation to confirm user-facing availability."
      num_results: 8
    
    internal_docs_retriever:
      name: "internal_docs_retriever"
      description: "Retrieves internal troubleshooting documents, error guides, architecture diagrams, and company-specific Lakebridge knowledge. Use this for error resolution, known issues, internal procedures, and non-public documentation. Information includes tables, figures, and detailed problem-solution mappings."
      num_results: 10

# Code Summarization Configuration
codebase_ingestion:
  summarization_prompt: "You are optimized to generate accurate descriptions for given Python or SQL codes. The code is part of the Lakebridge assessment library (for DBSQL Migration from other databases to Databricks). When the user inputs the code, you must return the description according to its goal and functionality. You are not allowed to generate additional details. The user expects at least 5 sentence-long descriptions. Do not mention again in the summary that this is part of the Lakebridge assessment library. Do not make assumptions. Here is the code: "

# Evaluation Example. Used while building the agent as a quick test.
evaluation:
  dataset:
    - inputs:
        input:
          - role: "user"
            content: "Can Lakebridge migrate tables from external to managed?"
      expected_response: "Lakebridge cannot migrate from external DELTA tables to managed. It is centered on the idea of migrating from one database to another, not from one storage format to another."

# Deployment Configuration (used by Databricks Apps and webapp)
# These values can be overridden by environment variables in app.yaml:
#   - SERVING_ENDPOINT overrides serving_endpoint
#   - AUDIT_TABLE overrides audit_table  
#   - AUDIT_DEBUG overrides audit_debug
deployment:
  serving_endpoint: "agents_repo_assistants-default-lakebridge_agent"
  audit_table: "repo_assistants.default.lakebridge_chat_interactions"  # Format: catalog.schema.table
  audit_debug: false

